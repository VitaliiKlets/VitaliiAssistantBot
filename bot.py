import logging
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from openai import OpenAI
import os

# –õ–û–ì–Ü–ù–ì –¥–ª—è –¥–µ–±–∞–≥—É
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)

# –ë–ï–†–ï–ú–û –ö–õ–Æ–ß–Ü
TELEGRAM_TOKEN = os.getenv("BOT_TOKEN")  # —Ç–≤—ñ–π Telegram-—Ç–æ–∫–µ–Ω
OPENAI_KEY = os.getenv("OPENAI_API_KEY")  # —Ç–≤—ñ–π OpenAI API-–∫–ª—é—á

# –°–¢–í–û–†–Æ–Ñ–ú–û –ö–õ–Ü–Ñ–ù–¢–ê OpenAI
client = OpenAI(api_key=OPENAI_KEY)


# /start –∫–æ–º–∞–Ω–¥–∞
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤—ñ—Ç! –Ø —Ç–≤—ñ–π AI-–±–æ—Ç. –ù–∞–ø–∏—à–∏ –º–µ–Ω—ñ —â–æ—Å—å üòâ")


# –û–ë–†–û–ë–ö–ê –í–°–Ü–• –ü–û–í–Ü–î–û–ú–õ–ï–ù–¨
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text

    try:
        # –í–ò–ö–õ–ò–ö OpenAI
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "–¢–∏ –¥—Ä—É–∂–Ω—ñ–π Telegram-–±–æ—Ç."},
                {"role": "user", "content": user_message},
            ],
            max_tokens=300,
            temperature=0.7,
        )

        reply = response.choices[0].message.content
        await update.message.reply_text(reply)

    except Exception as e:
        logging.error(f"OpenAI Error: {e}")
        await update.message.reply_text("‚ö†Ô∏è –í–∏–±–∞—á, —Å—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –æ–±—Ä–æ–±—Ü—ñ —Ç–≤–æ—î—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ.")


# –ì–û–õ–û–í–ù–ê –§–£–ù–ö–¶–Ü–Ø
def main():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    # –ö–æ–º–∞–Ω–¥–∏
    app.add_handler(CommandHandler("start", start))

    # –í—Å—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # –ó–∞–ø—É—Å–∫
    app.run_polling()


if __name__ == "__main__":
    main()
